{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6909268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from manga_ocr.utils import get_path_project_dir\n",
    "from manga_ocr.utils.pytorch_model import get_total_parameters_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb37c50",
   "metadata": {},
   "source": [
    "# Load/Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089bedc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_output_model /Users/wanasit/Dropbox/Workspace_Personal/manga-ocr/data/output/models/localization.bin\n",
      "Loading an existing model...\n",
      "ConvUnet(\n",
      "  (down_conv_3): ConvWithPoolingToHalfSize(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (down_conv_2): ConvWithPoolingToHalfSize(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (down_conv_1): ConvWithPoolingToHalfSize(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (down_conv_0): ConvWithPoolingToHalfSize(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (up_conv1): DoubleConvWithSecondInput(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_conv2): DoubleConvWithSecondInput(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (up_conv3): DoubleConvWithSecondInput(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (output_conv_char): Sequential(\n",
      "    (0): Conv2d(35, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (output_conv_line): Sequential(\n",
      "    (0): Conv2d(35, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from manga_ocr.models.localization.conv_unet.conv_unet import ConvUnet\n",
    "\n",
    "path_output_model = get_path_project_dir('data/output/models/localization.bin')\n",
    "print('path_output_model', os.path.abspath(path_output_model))\n",
    "\n",
    "if os.path.exists(path_output_model):\n",
    "    print('Loading an existing model...')\n",
    "    model = torch.load(path_output_model)\n",
    "else:\n",
    "    print('Creating a new model...')\n",
    "    model = ConvUnet()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158ab6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n",
      "399490\n"
     ]
    }
   ],
   "source": [
    "print(model.image_size)\n",
    "print(get_total_parameters_count(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f71451",
   "metadata": {},
   "source": [
    "## Load/Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7812cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_dataset /Users/wanasit/Dropbox/Workspace_Personal/manga-ocr/data/output/generate_manga_dataset\n",
      "dataset 4000\n"
     ]
    }
   ],
   "source": [
    "from manga_ocr.models.localization.localization_dataset import LocalizationDataset\n",
    "\n",
    "path_dataset = get_path_project_dir('data/output/generate_manga_dataset')\n",
    "print('path_dataset', os.path.abspath(path_dataset))\n",
    "\n",
    "dataset = LocalizationDataset.load_generated_manga_dataset(path_dataset, image_size=model.image_size)\n",
    "print('dataset', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a6a25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_dataset 100\n",
      "training_dataset 3900\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = dataset.subset(to_idx=100)\n",
    "training_dataset = dataset.subset(from_idx=100)\n",
    "print('validation_dataset', len(validation_dataset))\n",
    "print('training_dataset', len(training_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab915c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79b5e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from manga_ocr.models.localization.train import train\n",
    "from manga_ocr.utils.ploting import plot_losses, show_images\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_example(model, img):\n",
    "    img_mask = model.create_image_mark_lines(img)\n",
    "    show_images(images=[img, img_mask], texts=['input', 'output'], figsize=(10, 10))\n",
    "\n",
    "\n",
    "def save_and_report(i_epoch, train_losses, val_losses):\n",
    "    clear_output()\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    show_example(model, training_dataset.images[0])\n",
    "    show_example(model, validation_dataset.images[0])\n",
    "    \n",
    "    torch.save(model, path_output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1711e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%| | 10/3900 [00:20<2:15:54,  2.10s/it, training_batch_loss=0.00283]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepoch_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_and_report\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepoch_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/Workspace_Personal/manga-ocr/notebooks/../manga_ocr/models/localization/train.py:46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, training_dataset, validation_dataset, epoch_count, epoch_callback, tqdm_disable, batch_size, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(batch)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m current_batch_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Workspace_VMs/anaconda3/envs/ocr/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace_VMs/anaconda3/envs/ocr/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,\n",
    "      training_dataset=training_dataset,\n",
    "      validation_dataset=validation_dataset,\n",
    "      epoch_callback=save_and_report,\n",
    "      epoch_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c928bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
